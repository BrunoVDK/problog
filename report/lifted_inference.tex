\fakesection{Lifted Inference}

%%%
%%%
%%%

\fakesubsection{Calculating Probability with Probabilistic Databases}

\noindent Starting from the following probabilistic database tables :

\begin{table}[h]

	\centering
	
	\begin{subtable}{.2\linewidth}{
	\centering
	\begin{tabular}{c|c}
		$X$ & $\underline{stress(X)}$\\
		$a$ & 0.2\\
		$b$ & 0.2\\
		$c$ & 0.2
	\end{tabular}}
	\label{tab:1a}
	\end{subtable}
	\begin{subtable}{.3\linewidth}{
	\centering
	\begin{tabular}{cc|c}
		$X$ & $Y$ & $\underline{friends(X,Y)}$\\
		$a$ & $b$ & 0.1\\
		$a$ & $c$ & 0.1\\
		$b$ & $c$ & 0.1\\
		$c$ & $b$ & 0.1\\
	\end{tabular}}
	\label{tab:2a}
	\end{subtable}
	\begin{subtable}{.2\linewidth}{
	\centering
	\begin{tabular}{c|c}
		$X$ & $\underline{p(X)}$\\
		$a$ & 0.3\\
		$b$ & 0.3\\
		$c$ & 0.3\\
	\end{tabular}}
	\label{tab:3a}
	\end{subtable}
	\begin{subtable}{.2\linewidth}{
	\centering
	\begin{tabular}{cc|c}
		$X$ & $Y$ & $\underline{p(X,Y)}$\\
		$a$ & $b$ & 0.4\\
		$a$ & $c$ & 0.4\\
		$b$ & $c$ & 0.4\\
		$c$ & $b$ & 0.4\\
	\end{tabular}}
	\label{tab:4a}
	\end{subtable}

	\caption{Probabilistic database to be used for querying.}\label{tab:probdata}

\end{table}

\noindent Querying for $smokes(a)$ can be done as follows :
$$(stress(a)\ \land\ p(a))\ \lor\ (\exists x: p(a,x)\ \land\ friends(a,x)\ \land\ ((stress(x)\ \land\ p(x))\ \lor\ \exists y: p(x,y)\ \land\ friends(x,y)\ \land\ stress(y)\ \land\ p(y)))$$
Rules can be applied to this formula. Applying the inclusive or rule gives :
\begin{gather*}
1-(1-p_{stress(a)\ \land\ p(a)})\times (1-p_{s_1})
\end{gather*}
Where $s_1$ refers to the subformula for the first existential operator. The probability $p_{s_1}$ cannot simply be calculated by exponentiation as the various instantiations of $s_1$ are dependent. However, there are only two such instantiations (for $smokes(a)$ and $smokes(b)$) and since the existential operator generalises the logical or, the formula for exclusive or can directly be used instead :
\begin{gather*}
p_{s_1} = p_{friends(a,b)}\times p_{p(a,b)}\times p_{smokes(b)} + p_{friends(a,c)}\times p_{p(a,c)}\times p_{smokes(c)} - p_{both}
\end{gather*}
Where $p_{both}=p_{friends(a,b)}\ \land\ p_{p(a,b)}\ \land\ p_{friends(a,c)}\ \land\ p_{p(a,c)}\ \land\ p_{smokes(b)}\ \land\ p_{smokes(c)}$. The probability of either $smokes(b)$ or $smokes(c)$ is the same (as is the probability of $friends(a,b)\ \land\ p(a,b)$ and $friends(a,c)\ \land\ p(a,c)$, so this reduces to :
\begin{gather*}
p_{s_1} = 2\times p_{friends(a,b)}\times p_{p(a,b)}\times p_{smokes(b)} - p_{friends(a,b)\ \land\  friends(a,c)\ \land\ smokes(b)\ \land\ smokes(c)}
\end{gather*}
The probability of $smokes(b)$ can be calculated using the same rules (an inclusive or and the and-rule) :
\begin{gather*}
1-(1-p_{stress(b)}\times p_{p(b)})\times (1-p_{friends(b,c)}\times p_{p(b,c)}\times p_{stress(c)}\times p_{p(c)})\\
= (1-(1-0,2\times 0,3)\times (1-0,1\times 0,4\times 0,3\times 0,2)\\
\approx 0.62256
\end{gather*}
The probability of $p_{smokes(b)\ \land\ smokes(c)}$ can also be calculated with these rules, for example :
\begin{gather*}
p_{smokes(b)\ \land\ smokes(c)} \\
= p_{stress(b)\ \land\ p(b)\ \land\ smokes(c)} + p_{stress(c)\ \land\ p(c)\ \land\ smokes(b)} - p_{all}\\
= 2\times p_{stress(b)}\times p_{p(b)}\times (p_{stress(c)\ \land\ p(c)}+p_{friends(b,c)\ \land\ p(b,c)}-p_{stress(c)\ \land\ p(c)\ \land\ friends(b,c)\ \land\ p(b,c)})\\
- p_{stress(b)}\times p_{p(b)}\times p_{stress(c)}\times p_{p(c)}
\end{gather*}
The probability of $p_{stress(a)\ \land\ p(a)}$ equals $p_{p(a)}\times p_{stress(a)}$.
After filling in all the missing probabilities of the involved literals (by looking them up in the database) the following total probability is obtained :
% 1-(1-0,2*0,3)*(1-(2*0,1*0,4*(1-(1-0,2*0,3)*(1-0,1*0,4*0,3*0,2))-0,1*0,4*0,4*0,1*(0,2*0,3*(0,2*0,3+0,1*0,4-0,2*0,3*0,1*0,4)+0,2*0,3*(0,2*0,3+0,1*0,4-0,2*0,3*0,1*0,4)-0,2*0,3*0,2*0,3)))
\begin{gather*}
1-(1-0,2\times 0,3)\times (1-(2\times 0,1\times 0,4\times (1-(1-0,2\times 0,3)\times (1-0,1\times 0,4\times 0,3\times 0,2))-\\
0,1\times 0,4\times 0,1\times 0,4\times (0,2\times 0,3\times (0,2\times 0,3+0,1\times 0,4-0,2\times 0,3\times 0,1\times 0,4)+0,2\times 0,3\times\\ 
(0,2\times 0,3+0,1\times 0,4-0,2\times 0,3\times 0,1\times 0,4)-0,2\times 0,3\times 0,2\times 0,3)))\\
\approx 0,06466945075
\end{gather*}This is the same number as the one previously found by the weighted model counters. Some symmetry was taken advantage of.

\fakesubsection{Skolemization \& Noisy OR}

A new encoding can be made by, instead of converting the formula $X\Leftrightarrow Y_1\lor Y_2 \lor ... \lor Y_n$ to CNF in the usual way, applying a Tseitin transformation. This leads to :
\begin{gather*}
X \lor \lnot Y_1\\
X \lor \lnot Y_2\\
...\\
X \lor \lnot Y_n\\
X \lor T\\
T \lor \lnot Y_1\\
T \lor \lnot Y_2\\
...\\
T \lor \lnot Y_n
\end{gather*}
Applying this transformation to the noisy OR relations in the encoding lead to a slightly \textit{larger} circuit though, when tested with a program in which there were more ancestors, the resulting circuits were \textit{smaller}.