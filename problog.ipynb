{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMqVpZe1wgUC08/Yu9SSuKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoVandekerkhove/problog/blob/master/problog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7GJRGYYmMqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "215e987f-833b-4780-bce2-a07155e36026"
      },
      "source": [
        "pip install problog"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting problog\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/58/02f13a74035a61b6bf34569ca93c3271f92d7537646455ab7a6b15fd92f7/problog-2.1.0.39.tar.gz (920kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: problog\n",
            "  Building wheel for problog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for problog: filename=problog-2.1.0.39-cp36-none-any.whl size=1191354 sha256=d260c266e601148b8114a913f17c19dbe3ba98c3559b89f027dc48bb041bb87d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/39/8b/94d87db45d73434ef72f196b05131f9920df075fc6203aebdc\n",
            "Successfully built problog\n",
            "Installing collected packages: problog\n",
            "Successfully installed problog-2.1.0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u43ioR6m-fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from problog.program import PrologString, LogicProgram\n",
        "from problog.formula import LogicFormula, LogicDAG\n",
        "from problog.logic import Term\n",
        "from problog.ddnnf_formula import DDNNF\n",
        "from problog.cnf_formula import CNF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K455IxwWlkWE",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic Inference using WMC\n",
        "\n",
        "One of the most performant techniques to compute the marginal or conditional probability of a query given a probabilistic graphical model (PGM) or probabilistic programs is to reduce the problem to weighted model counting (WMC). This entails that a PGM such as a Bayesian network is represented as a propositional knowledge base in conjunctive normal form (CNF) with weights associated to the propositional variables. You will build a small compiler based on such approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVg54KywltqG",
        "colab_type": "text"
      },
      "source": [
        "#### SRL to CNF\n",
        "\n",
        "ProbLog, a Statistical Relational Learning formalism, is a generalization of PGM that allows one to express complex re- lations. Similar to PGMs, probabilistic inference for ProbLog can be reduced to a Weighted Model Counting task. Read about this approach in Fierens et al. [2015] (sections 1-6.1).\n",
        "\n",
        "*   ***Task 1.1.1*** Write the encoding for the ProbLog program as logic formula and associated weights.For partial credit youcan restrict the friends relationships to 0.1::friends(a,b) and 0.1::friends(a,c) to avoid cycles (also for the next tasks).\n",
        "*   ***Task 1.1.2*** Show the intermediate steps to translate the given program to a CNF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIwhptjRlipi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c52bc1a7-d219-4031-a5f0-3666f0eb0bb2"
      },
      "source": [
        "p = PrologString(\"\"\"\n",
        "person(a). \n",
        "person(b). \n",
        "person(c). \n",
        "0.2::stress(X) :- person(X). \n",
        "0.1::friends(X,Y) :- person(X), person(Y). \n",
        "0.3::smokes(X) :- stress(X). \n",
        "0.4::smokes(X) :- friends(X,Y), smokes(Y). \n",
        "query(smokes(a)).\n",
        "\"\"\")\n",
        "lf2 = LogicFormula.create_from(p, avoid_name_clash=True, keep_order=True, label_all=True)\n",
        "# print(LogicFormula.to_prolog(lf2))\n",
        "dag2 = LogicDAG.create_from(lf2, avoid_name_clash=True, keep_order=True, label_all=True)\n",
        "# print(dag2)\n",
        "print(LogicFormula.to_prolog(dag2))\n",
        "cnf2 = CNF.create_from(dag2)\n",
        "# for clause in cnf2._clauses:\n",
        "#     print(clause)\n",
        "ddnnf2 = DDNNF.create_from(cnf2)\n",
        "print(ddnnf2.evaluate())\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2::stress(a).\n",
            "0.3::smokes(a) :- stress(a).\n",
            "0.1::friends(a,b).\n",
            "0.2::stress(b).\n",
            "0.1::friends(b,c).\n",
            "0.2::stress(c).\n",
            "0.3::_problog_smokes_cb_0(c) :- stress(c).\n",
            "0.1::friends(c,b).\n",
            "0.4::smokes(a) :- friends(a,b), node_15.\n",
            "0.1::friends(a,c).\n",
            "0.4::smokes(a) :- friends(a,c), _problog_smokes_cb_0(c).\n",
            "0.3::choice(24,0,smokes(b),b).\n",
            "0.4::choice(33,0,smokes(c),c,b).\n",
            "0.4::choice(33,0,smokes(b),b,c).\n",
            "query(smokes(a)).\n",
            "{smokes(a): 0.06466945075200001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJA372Wrl1uB",
        "colab_type": "text"
      },
      "source": [
        "#### SRL to PGM\n",
        "\n",
        "A ProbLog program can be translated to an equivalent Bayesian network. In ProbLog, multiple rules with the same head can be considered as a noisy-OR structure in PGM [Díez and Druzdzel, 2006, Sec 4.1.1]. You can also use the ProbLog tutorial for inspiration.\n",
        "\n",
        "\n",
        "*   ***Task 1.2.1*** Show a complete and correct equivalent Bayesian network for the given ProbLog program and query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UKZcOlBl5gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ03-Z4Cl6Az",
        "colab_type": "text"
      },
      "source": [
        "#### PGM to CNF\n",
        "\n",
        "Read about this approach in Chavira and Darwiche [2008] (sections 1-3, optionally also 4) and familiarize yourself with ENC1 (the encoding of Chavira and Darwiche) and ENC2 (the encoding of Sang, Beam and Kautz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYW9CHRlmImH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyjpANzamI4T",
        "colab_type": "text"
      },
      "source": [
        "#### Weighted Model Counting\n",
        "\n",
        "WMC can be performed by applying a search algorithm on the CNF or by compiling the CNF into a structure on which WMC can be performed in polynomial time with respect to the size of the structure. An advantage of the standardization to CNF is that multiple model counters can be applied, each with their own advantages and disadvantages. An exhaustive overview of exact model counters is available on http://beyondnp.org."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80P0V2ZAmLCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCUNCxNEmf2t",
        "colab_type": "text"
      },
      "source": [
        "### Lifted Inference\n",
        "\n",
        "In this part, you are tasked with applying lifted inference concepts to the models discussed before. Use the rules intro- duced in the lecture slides. You can also use the approach by Van den Broeck et al. [2014]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSX55Q_pmhyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXy9nlD5mh6g",
        "colab_type": "text"
      },
      "source": [
        "### Parameter Learning\n",
        "\n",
        "One of the key tasks in machine learning is learning the parameters that fit a given dataset. In this task you implement your own Expectation-Maximisation learning algorithm based on Gutmann et al. [2011]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo2T83y_mk09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}